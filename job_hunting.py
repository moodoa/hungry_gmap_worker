import requests
from bs4 import BeautifulSoup


class JOB:
    def __init__(self, keyword, city):
        city_codes = {
            "å°åŒ—å¸‚": "6001001000",
            "æ–°åŒ—å¸‚": "6001002000",
            "æ¡ƒåœ’å¸‚": "6001003000",
            "å°ä¸­å¸‚": "6001004000",
            "å°å—å¸‚": "6001005000",
            "é«˜é›„å¸‚": "6001006000",
            "å®œè˜­ç¸£": "6001007000",
            "æ–°ç«¹å¸‚": "6001008000",
            "æ–°ç«¹ç¸£": "6001008000",
            "è‹—æ —ç¸£": "6001010000",
            "å½°åŒ–ç¸£": "6001011000",
            "å—æŠ•ç¸£": "6001012000",
            "é›²æ—ç¸£": "6001013000",
            "å˜‰ç¾©ç¸£": "6001014000",
            "å˜‰ç¾©å¸‚": "6001014000",
            "å±æ±ç¸£": "6001016000",
            "å°æ±ç¸£": "6001017000",
            "èŠ±è“®ç¸£": "6001018000",
            "é‡‘é–€ç¸£": "6001020000",
            "æ¾æ¹–ç¸£": "6001021000",
            "åŸºéš†å¸‚": "6001009000",
            "æ–°ç«¹å¸‚": "6001019000",
            "å˜‰ç¾©å¸‚": "6001020000",
            "é€£æ±Ÿç¸£": "6001022000",
            "å…¨éƒ¨åœ°å€": "6001000000",
        }
        self.keyword = keyword
        self.city_code = city_codes[city]

    def hunting(self, page):
        url = "https://www.104.com.tw/jobs/search/"
        params = {
            "keyword": self.keyword,
            "area": self.city_code,
            "order": "1",
            "asc": "1",
            "page": page,
            "mode": "s",
        }
        response = requests.get(url, params=params)
        soup = BeautifulSoup(response.text, "html.parser")
        jobs = soup.find_all("article", {"class": "js-job-item"})
        return jobs

    def collect_jobs(self, cnt):
        page = 1
        jobs_infos = []
        while len(jobs_infos) < cnt:
            jobs = self.hunting(page)
            if not jobs:
                break
            jobs_infos += self.parse_soup(jobs)
            page += 1
            if len(jobs_infos) >= cnt:
                break
        return sorted(jobs_infos[:cnt], key=lambda x: x["job_date"], reverse=True)

    def parse_soup(self, jobs):
        jobs_infos = []
        for job in jobs:
            jobs_info = {}
            try:
                if job.find("span", {"class": "b-tit__date"}).text.strip() != "":
                    jobs_info["job_title"] = job.find(
                        "a", {"class": "js-job-link"}
                    ).text
                    jobs_info["job_link"] = job.find("a", {"class": "js-job-link"})[
                        "href"
                    ][2:]
                    jobs_info["job_company"] = job["data-cust-name"]
                    jobs_info["job_location"] = (
                        job.find("ul", {"class": "job-list-intro"})
                        .find_all("li")[0]
                        .text
                    )
                    jobs_info["job_salary"] = job.find(
                        "span", {"class": "b-tag--default"}
                    ).text
                    jobs_info["job_date"] = job.find(
                        "span", {"class": "b-tit__date"}
                    ).text.strip()
                    jobs_infos.append(jobs_info)
            except:
                pass
        return jobs_infos

    def make_output(self, jobs_infos):
        output = ""
        for jobs_info in jobs_infos:
            output += "ğŸª“\n"
            output += f"{jobs_info['job_title']}\n\n"
            output += f"{jobs_info['job_company']}\n\n"
            output += f"{jobs_info['job_location']}\n\n"
            output += f"{jobs_info['job_salary']}\n\n"
            output += f"æ›´æ–°æ—¥æœŸ: {jobs_info['job_date']}\n\n"
            output += f"{jobs_info['job_link']}\n\n\n"
        return output